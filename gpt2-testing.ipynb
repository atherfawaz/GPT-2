{"cells":[{"cell_type":"markdown","source":["<h1>Use this notebook to test generation and training code</h1>\r\n","\r\n","<p>Edit and run test.py to test anything that is not VM-specific. You can test generation, parameters, training code, and S3 bucket fetching with this notebook.</p>"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["#setup\r\n","!git clone https://github.com/WasiqMalik/gcloud-gpt-2.git\r\n","%cd gcloud-gpt-2\r\n","!pip install -r requirements.txt"],"outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"code","source":["#change directory\n","#%cd /mnt/batch/tasks/shared/LS_root/mounts/clusters/gptcomputeinstance/code/Users/atherfawaz/gcloud-gpt-2/gcloud-gpt-2\n","%cd gcloud-gpt-2/gcloud-gpt-2"],"outputs":[{"output_type":"stream","name":"stdout","text":["/mnt/batch/tasks/shared/LS_root/mounts/clusters/gptcomputeinstance/code/Users/atherfawaz/gcloud-gpt-2/gcloud-gpt-2\n"]}],"execution_count":1,"metadata":{}},{"cell_type":"markdown","source":["<h2>For testing the code file directly</h2>"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["!python writeMe.py"],"outputs":[{"output_type":"stream","name":"stdout","text":["07/14/2020 15:18:01 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-xl-config.json from cache at /home/azureuser/.cache/torch/transformers/289a4dd9ea41e5a898f64d60eab036a397782139e40973fa0b48844d9c0be2a8.8d57f9f1ff1beed2b81d9f0c99b4be29e800041e86c80cd90c2413051caa5dfb\n","07/14/2020 15:18:01 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 1600,\n","  \"n_head\": 25,\n","  \"n_layer\": 48,\n","  \"n_positions\": 1024,\n","  \"output_past\": true,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"vocab_size\": 50257\n","}\n","\n","07/14/2020 15:18:01 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-xl-pytorch_model.bin from cache at /home/azureuser/.cache/torch/transformers/e712b8a75b3752552c60575c8cf7405e4a581aefcd3bfce456c2f6d390e1409a.7013c97af6a899790dfb77a9d9b5230945da1f17f0b79da57a8941eaa3be03ca\n","07/14/2020 15:18:54 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'h.24.attn.masked_bias', 'h.25.attn.masked_bias', 'h.26.attn.masked_bias', 'h.27.attn.masked_bias', 'h.28.attn.masked_bias', 'h.29.attn.masked_bias', 'h.30.attn.masked_bias', 'h.31.attn.masked_bias', 'h.32.attn.masked_bias', 'h.33.attn.masked_bias', 'h.34.attn.masked_bias', 'h.35.attn.masked_bias', 'h.36.attn.masked_bias', 'h.37.attn.masked_bias', 'h.38.attn.masked_bias', 'h.39.attn.masked_bias', 'h.40.attn.masked_bias', 'h.41.attn.masked_bias', 'h.42.attn.masked_bias', 'h.43.attn.masked_bias', 'h.44.attn.masked_bias', 'h.45.attn.masked_bias', 'h.46.attn.masked_bias', 'h.47.attn.masked_bias', 'lm_head.weight']\n","07/14/2020 15:18:57 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-xl-config.json from cache at /home/azureuser/.cache/torch/transformers/289a4dd9ea41e5a898f64d60eab036a397782139e40973fa0b48844d9c0be2a8.8d57f9f1ff1beed2b81d9f0c99b4be29e800041e86c80cd90c2413051caa5dfb\n","07/14/2020 15:18:57 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 1600,\n","  \"n_head\": 25,\n","  \"n_layer\": 48,\n","  \"n_positions\": 1024,\n","  \"output_past\": true,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"vocab_size\": 50257\n","}\n","\n","07/14/2020 15:18:57 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-xl-vocab.json from cache at /home/azureuser/.cache/torch/transformers/eb2d31fb18c927045d8ccc07cace8bf1c10458bf171a5ad4cb1cbe0b75773425.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","07/14/2020 15:18:57 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-xl-merges.txt from cache at /home/azureuser/.cache/torch/transformers/18d7ac53606f670f979f24836b00f5dfee1c58d79bdbcc58411265f194d88ac0.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","07/14/2020 15:18:57 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","\n","------------------NEW SAMPLE--------------------\n","\n","Once upon a time there a poet. He lived in Cape Canaveral, Florida. So famous was he that he had his own song and all the men of science laughed at him\n","\n","The poet was not known to other poets, but as many people know it was he who told an old friend from Baltimore to get an astronomer's telescope so he could read poetry like they used to do back then. When astronomy fell into disrepute because it did not produce visible light - as we now know it is now doing thanks to Galileo's heliocentric law of change that showed us the true orbit of Jupiter around its star - the astronomer took up writing poems about space. They were published anonymously under different names in numerous books, for example \"Of Spaceships And Astronomical Observations.\" However when the poems of the astronomer caught wind of the old friend's interest he realized the mistake he had made, asked the other astronomers if he should correct this error and got no reply, while continuing to write poems in both the modern language and ancient Greek verse. The only thing that remained was the name Dr. John Wilkins, or some variation thereof.\n","\n","\n","This poem (which does contain references to solar eclipses, among other things) has many similarities with Homer's The Odyssey. It tells the story of Odysseus' journey across the ocean (not through time), which leads to the most memorable scene in literature, being swallowed by a whale in a storm, though he survives somehow. (Note the similarity with Odysseus's first voyage.) Of course I am unaware of any evidence that anyone ever actually called them this. Also note that Homer's original works are lost; the book that bore his name was destroyed during the sack of Athens by the Athenians. In fact even Odysseus is described in the Odyssey as having returned home before he could tell the tale, where all the action happens!\n","\n","\n","So why the use of 'old poem'? Did someone really mean Ancient Greek verse? Perhaps. This might explain how Homer came to be considered as ancient as The Bible, but even scholars are very doubtful he intended it that way:\n","\n","\n","\"No proof of Homeric authorship [from the earliest times] has been found... There has never come on record an attempt to make sense of them by comparison with anything written later (Kruger 1989, p. 453 n.; Ruhl 1961, pp. 35-37). Only two centuries after the publication of the Odyssey -- nearly 700 years after Homer's death -- the classical\n","\n","------------------NEW SAMPLE--------------------\n","\n","Once upon a time there a poet. He lived in Cape Canaveral, Florida.\n","\n","The day dawned cold and gray, and he lay in a hammock out back with his poetry books on. A lonely old woman visited him from one of the bars around town; she was a hard drinking bint (a member of an Arab tribe, who speak of them as \"barbeque\") and carried her shotgun about all night because she never knew when night would last forever, and she wanted to make sure this man had at least one weapon with which to defend himself before it changed again into darkness.\n","\n","She listened intently for what poetry could say and was very impressed. She told him so offhand that a bit more information had to be collected: that the word for \"night\" was called chasma, and also described by its Greek roots as \"wandering.\" This meant that when \"suddenly\" something happened like lightning breaking through the storm clouds or wind blowing across the river or an attack from some animal or enemy plane, all those things happening during the same instant were said to happen over night. And since all these things did not occur exactly at midnight, you had to go down under the sea to find the new moon at three in the morning if you expected to see it and hope to sleep well in your bed with your wife under another hammock, but you had come too far up here already when daylight came just after three in the morning. The poet took this story as gospel and got drunk on wine while talking to the old woman long enough to get ready his poem. His poem, I think we'll call it \"I Was Once Lonely As a Rock,\" was really pretty good. It tells very good stories of how our planet works, not only as seen from above, but from within as well: the process of aging is revealed with every blink, and the process of death unfolds slowly and quietly in the dark. To make this poem seem especially serious and urgent the poet wrote it long after midnight, when no other person on earth thought they slept at all.\n","\n","When he was done singing the words together and putting the final touches on the work his partner left the room. The old Indian was angry—a deep simmering anger that bubbled over as he turned around to look at me. We looked at each other, then both set to walking away. In my mind's eye, I watched them stumble and turn. A moment later the stranger appeared, smiling benignly, still carrying the book in his hand.\n","\n","------------------NEW SAMPLE--------------------\n","\n","Once upon a time there a poet. He lived in Cape Canaveral, Florida. He could remember the first times he used to run on the beach at St. Pete Beach. At nine this was easy for him! He loved it! Soon after that the clouds opened and everything became dark except for his friend running in the sea below. How soon the world has gone by you ask? Fifteen years ago, when he was fourteen he walked on stage at school, won gold medals all over town as an amateur ice skater and went to University one year before he died. Then came the tragedy and many nights were spent alone, crying and waiting for news of his mother. For seven months no word or noise came from her but what seemed to be her breathing: \"I'm just sleeping I'm very anxious.\" When she finally did wake up every night she could not say why. Finally one day she told him that, since they have never found who committed this crime against her, he must go get some help. A doctor would do her good but that's nothing; if it's only just a break then he'll take care of himself too when we're done with him.\n","\n","The most amazing thing about life. If you can find out what is the real and just cause of a disaster such as a nuclear power plant accident, don't just give a press release and claim insurance payout. If anyone really wants to get even as much money out of these people as possible they can hire me to go find them before they pull the plug. The more information I have the better, because they will get more frightened and afraid which in turn will increase their vulnerability to whatever comes next.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n","\n","------------------NEW SAMPLE--------------------\n","\n","Once upon a time there a poet. He lived in Cape Canaveral, Florida.\n","\n","We all know the story of how he wrote it down and then found someone to read it out loud when its authorship was discovered. His work is still being played at the annual Cape Canaveral International Film Festival at which each year his name will be shouted from the rafters, but no one pays tribute to him by reading what he wrote. The man who has made \"a lot better poems than anybody alive\" according to the New York Times only wants an audience of people who have already been born. His works are for dead lovers! His poems become, as Robert Lowell famously put it, \"the last good words.\" In essence they offer only nostalgia but that doesn't even begin to describe their utter disregard for the present. Why should we celebrate the dead, especially when so many of us live? Because this sort of old-fashioned romanticism isn't just something that happens to white men during the height of their creativity. It happens all across America, to writers in black, brown and white bodies, but also every other kind of American writer: literary and otherwise. From the very beginning (although I don't doubt the validity of some of my criticisms here) I thought these critiques could be more nuanced if I included poetry and creative writing studies scholars around whom I speak as contributors. This project would include a close examination of contemporary art, including the ways in which certain kinds of images can affect our conceptions of ourselves and others from past generations along with what has come to be known among contemporary artists as \"decolonization,\" or the process of imagining the world through new eyes in order to make it recognizable again — as well as how such ideas often produce their own problems because of those same new eyes' need to see themselves reflected back into society. When you're trying to figure out what makes modern art \"work,\" you'd think I would draw on the most reputable sources possible to get the answers. But after writing this essay, I realize that's not even clear why the questions I've raised aren't even more relevant today than when I first encountered them nearly thirty years ago and many decades before when most of these scholars were either working inside institutions or conducting research within or near existing museums. If I'm supposed to write about the current state of modern arts criticism and how modern art can improve and enrich our lives if only it had a wider readership, shouldn't I be speaking to academics from both major disciplines? Who has done the best job explaining why a number of early twentieth century\n"]}],"execution_count":10,"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"markdown","source":["<h2>For testing the BERT summarizer directly</h2>"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["!python summerizer.py"],"outputs":[{"output_type":"stream","name":"stdout","text":["Once upon a time there a poet. He lived in Cape Canaveral, Florida. He could remember the first times he used to run on the beach at St. Pete Beach. At nine this was easy for him! He loved it! Soon after that the clouds opened and everything became dark except for his friend running in the sea below. How soon the world has gone by you ask? Fifteen years ago, when he was fourteen he walked on stage at school, won gold medals all over town as an amateur ice skater and went to University one year before he died. Then came the tragedy and many nights were spent alone, crying and waiting for news of his mother. For seven months no word or noise came from her but what seemed to be her breathing: \"I'm just sleeping I'm very anxious.\" When she finally did wake up every night she could not say why. Finally one day she told him that, since they have never found who committed this crime against her, he must go get some help. A doctor would do her good but that's nothing; if it's only just a break then he'll take care of himself too when we're done with him. The most amazing thing about life. If you can find out what is the real and just cause of a disaster such as a nuclear power plant accident, don't just give a press release and claim insurance payout. If anyone really wants to get even as much money out of these people as possible they can hire me to go find them before they pull the plug. The more information I have the better, because they will get more frightened and afraid which in turn will increase their vulnerability to whatever comes next\n","\n","He could remember the first times he used to run on the beach at St. Pete Beach. Soon after that the clouds opened and everything became dark except for his friend running in the sea below. A doctor would do her good but that's nothing; if it's only just a break then he'll take care of himself too when we're done with him\n"]}],"execution_count":19,"metadata":{}},{"cell_type":"markdown","source":["<h2>For testing the parameters directly</h2>"],"metadata":{"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":["!python test.py"],"outputs":[{"output_type":"stream","name":"stdout","text":["08/17/2020 08:22:38 - INFO - botocore.credentials -   Found credentials in shared credentials file: ~/.aws/credentials\n","08/17/2020 08:22:38 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-xl-config.json from cache at /home/azureuser/.cache/torch/transformers/289a4dd9ea41e5a898f64d60eab036a397782139e40973fa0b48844d9c0be2a8.8d57f9f1ff1beed2b81d9f0c99b4be29e800041e86c80cd90c2413051caa5dfb\n","08/17/2020 08:22:38 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 1600,\n","  \"n_head\": 25,\n","  \"n_layer\": 48,\n","  \"n_positions\": 1024,\n","  \"output_past\": true,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"vocab_size\": 50257\n","}\n","\n","08/17/2020 08:22:38 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-xl-pytorch_model.bin from cache at /home/azureuser/.cache/torch/transformers/e712b8a75b3752552c60575c8cf7405e4a581aefcd3bfce456c2f6d390e1409a.7013c97af6a899790dfb77a9d9b5230945da1f17f0b79da57a8941eaa3be03ca\n","08/17/2020 08:23:30 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'h.24.attn.masked_bias', 'h.25.attn.masked_bias', 'h.26.attn.masked_bias', 'h.27.attn.masked_bias', 'h.28.attn.masked_bias', 'h.29.attn.masked_bias', 'h.30.attn.masked_bias', 'h.31.attn.masked_bias', 'h.32.attn.masked_bias', 'h.33.attn.masked_bias', 'h.34.attn.masked_bias', 'h.35.attn.masked_bias', 'h.36.attn.masked_bias', 'h.37.attn.masked_bias', 'h.38.attn.masked_bias', 'h.39.attn.masked_bias', 'h.40.attn.masked_bias', 'h.41.attn.masked_bias', 'h.42.attn.masked_bias', 'h.43.attn.masked_bias', 'h.44.attn.masked_bias', 'h.45.attn.masked_bias', 'h.46.attn.masked_bias', 'h.47.attn.masked_bias', 'lm_head.weight']\n","08/17/2020 08:23:31 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-xl-config.json from cache at /home/azureuser/.cache/torch/transformers/289a4dd9ea41e5a898f64d60eab036a397782139e40973fa0b48844d9c0be2a8.8d57f9f1ff1beed2b81d9f0c99b4be29e800041e86c80cd90c2413051caa5dfb\n","08/17/2020 08:23:31 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"_num_labels\": 1,\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 1600,\n","  \"n_head\": 25,\n","  \"n_layer\": 48,\n","  \"n_positions\": 1024,\n","  \"output_past\": true,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"vocab_size\": 50257\n","}\n","\n","08/17/2020 08:23:31 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-xl-vocab.json from cache at /home/azureuser/.cache/torch/transformers/eb2d31fb18c927045d8ccc07cace8bf1c10458bf171a5ad4cb1cbe0b75773425.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","08/17/2020 08:23:31 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-xl-merges.txt from cache at /home/azureuser/.cache/torch/transformers/18d7ac53606f670f979f24836b00f5dfee1c58d79bdbcc58411265f194d88ac0.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","08/17/2020 08:23:31 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","-----GENERATED SAMPLE------\n","(0, 'Most neural models for audio generation are likelihood-based: they represent an explicit probability distribution and the likelihood of the observed data is maximised under this distribution. Autoregressive models achieve this by factorising the joint distribution into a product of conditional distributions (van den Oord et al., 2016; Mehri et al., 2017; Kalchbrenner et al., 2018; Arik et al., 2017). Another strategy is to use an invertible feed-forward neural network to model the joint density directly (Prenger et al., 2019; Kim et al., 2019). Alternatively, an invertible feed-forward model can be trained by distilling an autoregressive model using probability density distillation (van den Oord et al., 2018; Ping et al., 2019), which enables it to focus on particular modes. Such mode-seeking behaviour is often desirable in conditional generation settings: we want the generated speech signals to sound realistic and correspond to the given text, but we are not interested in modelling every possible variation that occurs in the data. This reduces model capacity requirements, because parts of the data distribution may be ignored. Note that adversarial models exhibit similar behaviour, but without the distillation and invertibility requirements. Many audio generation models, including all of those discussed so far, operate in the waveform domain: they directly model the amplitude of the waveform as it evolves over time. This is in stark contrast to most audio models designed for discriminative tasks (e.g. audio classification): such models tend to operate on time-frequency representations of audio (spectrograms), which encode certain inductive biases with respect to the human perception of sound, and usually discard all phase information in the signal. While phase information is often inconsequential for discriminative tasks, generated audio signals must have a realistic phase component, because fidelity as judged by humans is severely affected otherwise. Because no special treatment for the phase component of the signal is required when generating directly in the waveform domain, this is usually more practical. Tacotron (Wang et al., 2017) and MelNet (Vasquez & Lewis, 2019) constitute notable exceptions, and they use the Griffin-Lim algorithm (Griffin & Lim, 1984) to reconstruct missing phase information, which the models themselves do not generate. Models like Deep Voice 2 & 3 (Gibiansky et al., 2017; Ping et al., 2018) and Tacotron 2 (Shen et al., 2018) achieve a compromise by first generating a spectral representation, and then using a separate autoregressive model to turn it into a waveform and fill in any missing spectral information. Because the generated spectrograms are imperfect, the waveform model has the additional task of correcting any mistakes. Char2wav (Sotelo et al., 2017) uses intermediate vocoder features in a similar fashion. Although this technique does not correct all aspects of your')\n","-----GENERATED SAMPLE------\n","(1, 'Most neural models for audio generation are likelihood-based: they represent an explicit probability distribution and the likelihood of the observed data is maximised under this distribution. Autoregressive models achieve this by factorising the joint distribution into a product of conditional distributions (van den Oord et al., 2016; Mehri et al., 2017; Kalchbrenner et al., 2018; Arik et al., 2017). Another strategy is to use an invertible feed-forward neural network to model the joint density directly (Prenger et al., 2019; Kim et al., 2019). Alternatively, an invertible feed-forward model can be trained by distilling an autoregressive model using probability density distillation (van den Oord et al., 2018; Ping et al., 2019), which enables it to focus on particular modes. Such mode-seeking behaviour is often desirable in conditional generation settings: we want the generated speech signals to sound realistic and correspond to the given text, but we are not interested in modelling every possible variation that occurs in the data. This reduces model capacity requirements, because parts of the data distribution may be ignored. Note that adversarial models exhibit similar behaviour, but without the distillation and invertibility requirements. Many audio generation models, including all of those discussed so far, operate in the waveform domain: they directly model the amplitude of the waveform as it evolves over time. This is in stark contrast to most audio models designed for discriminative tasks (e.g. audio classification): such models tend to operate on time-frequency representations of audio (spectrograms), which encode certain inductive biases with respect to the human perception of sound, and usually discard all phase information in the signal. While phase information is often inconsequential for discriminative tasks, generated audio signals must have a realistic phase component, because fidelity as judged by humans is severely affected otherwise. Because no special treatment for the phase component of the signal is required when generating directly in the waveform domain, this is usually more practical. Tacotron (Wang et al., 2017) and MelNet (Vasquez & Lewis, 2019) constitute notable exceptions, and they use the Griffin-Lim algorithm (Griffin & Lim, 1984) to reconstruct missing phase information, which the models themselves do not generate. Models like Deep Voice 2 & 3 (Gibiansky et al., 2017; Ping et al., 2018) and Tacotron 2 (Shen et al., 2018) achieve a compromise by first generating a spectral representation, and then using a separate autoregressive model to turn it into a waveform and fill in any missing spectral information. Because the generated spectrograms are imperfect, the waveform model has the additional task of correcting any mistakes. Char2wav (Sotelo et al., 2017) uses intermediate vocoder features in a similar fashion. At a minimum, the new models represent sound in')\n","-----GENERATED SAMPLE------\n","(2, 'Most neural models for audio generation are likelihood-based: they represent an explicit probability distribution and the likelihood of the observed data is maximised under this distribution. Autoregressive models achieve this by factorising the joint distribution into a product of conditional distributions (van den Oord et al., 2016; Mehri et al., 2017; Kalchbrenner et al., 2018; Arik et al., 2017). Another strategy is to use an invertible feed-forward neural network to model the joint density directly (Prenger et al., 2019; Kim et al., 2019). Alternatively, an invertible feed-forward model can be trained by distilling an autoregressive model using probability density distillation (van den Oord et al., 2018; Ping et al., 2019), which enables it to focus on particular modes. Such mode-seeking behaviour is often desirable in conditional generation settings: we want the generated speech signals to sound realistic and correspond to the given text, but we are not interested in modelling every possible variation that occurs in the data. This reduces model capacity requirements, because parts of the data distribution may be ignored. Note that adversarial models exhibit similar behaviour, but without the distillation and invertibility requirements. Many audio generation models, including all of those discussed so far, operate in the waveform domain: they directly model the amplitude of the waveform as it evolves over time. This is in stark contrast to most audio models designed for discriminative tasks (e.g. audio classification): such models tend to operate on time-frequency representations of audio (spectrograms), which encode certain inductive biases with respect to the human perception of sound, and usually discard all phase information in the signal. While phase information is often inconsequential for discriminative tasks, generated audio signals must have a realistic phase component, because fidelity as judged by humans is severely affected otherwise. Because no special treatment for the phase component of the signal is required when generating directly in the waveform domain, this is usually more practical. Tacotron (Wang et al., 2017) and MelNet (Vasquez & Lewis, 2019) constitute notable exceptions, and they use the Griffin-Lim algorithm (Griffin & Lim, 1984) to reconstruct missing phase information, which the models themselves do not generate. Models like Deep Voice 2 & 3 (Gibiansky et al., 2017; Ping et al., 2018) and Tacotron 2 (Shen et al., 2018) achieve a compromise by first generating a spectral representation, and then using a separate autoregressive model to turn it into a waveform and fill in any missing spectral information. Because the generated spectrograms are imperfect, the waveform model has the additional task of correcting any mistakes. Char2wav (Sotelo et al., 2017) uses intermediate vocoder features in a similar fashion.\\n\\nGenerated Generators Besides existing generat')\n"]}],"execution_count":6,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"collapsed":true,"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}}}],"metadata":{"kernel_info":{"name":"python3-azureml"},"kernelspec":{"name":"python3-azureml","language":"python","display_name":"Python 3.6 - AzureML"},"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"nteract":{"version":"nteract-front-end@1.0.0"}},"nbformat":4,"nbformat_minor":4}